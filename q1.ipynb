{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T17:00:25.505040Z",
     "start_time": "2019-11-11T17:00:25.111619Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pyFOc3bz7r0f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "EXpZUiu77-mA",
    "outputId": "eed0254b-d233-498a-b95a-579dae855946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T17:00:25.901375Z",
     "start_time": "2019-11-11T17:00:25.604206Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ejZwFxmz7r0r"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = loadlocal_mnist(\"/content/gdrive/My Drive/ML/Assignment3/q1_dataset/train-images-idx3-ubyte\", \"/content/gdrive/My Drive/ML/Assignment3/q1_dataset/train-labels-idx1-ubyte\")\n",
    "test_x, test_y = loadlocal_mnist(\"/content/gdrive/My Drive/ML/Assignment3/q1_dataset/t10k-images-idx3-ubyte\", \"/content/gdrive/My Drive/ML/Assignment3/q1_dataset/t10k-labels-idx1-ubyte\")\n",
    "train_x = preprocessing.normalize(train_x)\n",
    "test_x = preprocessing.normalize(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:31:50.068462Z",
     "start_time": "2019-11-11T13:31:50.059293Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "td2XTGcn7r0y"
   },
   "outputs": [],
   "source": [
    "class Neural_Net:\n",
    "    def __init__(self, N=0, arr=[], activationF=\"relu\", alpha=0.1):\n",
    "        self.N = N\n",
    "        self.arr = arr\n",
    "        self.activationF = activationF\n",
    "        self.alpha = alpha\n",
    "        self.weight = []\n",
    "        self.bias = []\n",
    "        self.initialize_weights()\n",
    "        self.X = [None for i in range(self.N)]\n",
    "        self.labels = []\n",
    "        self.weightChange = [None for i in range(self.N-1)]\n",
    "        self.biasChange = [None for i in range(self.N-1)]\n",
    "        # print(len(self.X),self.weight,'\\n',self.bias)\n",
    "\n",
    "    def initialize_weights(self):\n",
    "\n",
    "        for j in range(1, self.N):\n",
    "            size = self.arr[j]\n",
    "            temp = 0.01*np.random.normal(0, 1, self.arr[j-1]*size)\n",
    "            temp = np.reshape(temp, (self.arr[j-1],size))\n",
    "            self.weight.append(temp)\n",
    "        for j in range(1, self.N):\n",
    "            size = self.arr[j]\n",
    "            self.bias.append(np.zeros((1, size)))\n",
    "\n",
    "    def fit(self,train_x, train_y, batch_size=32, epochs=100):\n",
    "        countBatches = int(train_x.shape[0]/batch_size)\n",
    "        err = []\n",
    "        for i in range(epochs):\n",
    "            err.append(1-self.score(train_x,train_y))\n",
    "            print(\"Epoch:\",i,'Training accuracy:',1-err[-1])\n",
    "            for j in range(countBatches):\n",
    "                train_batch = train_x[batch_size*j:batch_size*(j+1),:]\n",
    "                train_out = train_y[batch_size*j:batch_size*(j+1)]\n",
    "\n",
    "                OHL = np.zeros((train_batch.shape[0],10))\n",
    "\n",
    "                for k in range(batch_size):\n",
    "                    OHL[k,train_out[k]]=1\n",
    "                self.labels = OHL\n",
    "                self.feed_forward(train_batch)\n",
    "                self.back_prop()\n",
    "                # print(self.weightChange)\n",
    "                for k in range(self.N-1):\n",
    "                    # print('shapes:',self.weight[k].shape,self.weightChange[k].shape,self.bias[k].shape,self.biasChange[k].shape)\n",
    "                    # print(self.weightChange[k])\n",
    "                    self.weight[k] -= (self.alpha/batch_size)*self.weightChange[k]\n",
    "                    self.bias[k] -= (self.alpha/batch_size)*self.biasChange[k].sum(axis=0)\n",
    "        return err\n",
    "    def back_prop(self):\n",
    "        for i in range(self.N-1,0,-1):\n",
    "            if (i!=self.N-1):\n",
    "                p = self.X[i]\n",
    "                if (self.activationF == 'sigmoid'):\n",
    "                    p = self.sigmoidDiff(p)\n",
    "                elif (self.activationF == 'relu'):\n",
    "                    p = self.reluDiff(p)\n",
    "                elif (self.activationF == 'linear'):\n",
    "                    p = self.linearDiff(p)\n",
    "                else:\n",
    "                    p = self.tanhDiff(p)\n",
    "                pol = (self.biasChange[i] @ self.weight[i].T)*p\n",
    "                self.weightChange[i-1] = self.X[i-1].T @ pol\n",
    "                self.biasChange[i-1] = pol\n",
    "            else:\n",
    "                error = self.X[-1] - self.labels\n",
    "                wC = self.X[i-1].T @ error\n",
    "                self.weightChange[i-1] = wC\n",
    "                self.biasChange[i-1] = error\n",
    "\n",
    "    \n",
    "    def feed_forward(self,sample):\n",
    "        self.X[0] = sample\n",
    "        for i in range(self.N-1):\n",
    "            # print(i,'.',self.X[i].shape,self.weight[i].shape)\n",
    "            p = (self.X[i] @ self.weight[i] )\n",
    "            # print(p.shape,\"<- before add, bias shape->\",self.bias[i].shape)\n",
    "            p+=self.bias[i]\n",
    "            # print(p.shape,\"after add\")\n",
    "            if (i!=self.N-2):\n",
    "                if (self.activationF == 'sigmoid'):\n",
    "                    self.X[i+1] = self.sigmoid(p)\n",
    "                elif (self.activationF == 'relu'):\n",
    "                    self.X[i+1] = self.relu(p)\n",
    "                elif (self.activationF == 'linear'):\n",
    "                    self.X[i+1] = self.linear(p)\n",
    "                else:\n",
    "                    self.X[i+1] = self.tanh(p)\n",
    "            else:\n",
    "                self.X[i+1] = self.softmax(p)\n",
    "        return self.X\n",
    "\n",
    "    def predict(self,test_x):\n",
    "        self.X[0] = test_x\n",
    "        for i in range(self.N-1):\n",
    "            outs = self.X[i] @ self.weight[i]\n",
    "            if (i==self.N-2):\n",
    "                outs += self.bias[i]\n",
    "                outs = self.softmax(outs)\n",
    "                \n",
    "            else:\n",
    "                outs+= self.bias[i]\n",
    "                if (self.activationF == 'sigmoid'):\n",
    "                    outs = self.sigmoid(outs)\n",
    "                elif (self.activationF == 'relu'):\n",
    "                    outs = self.relu(outs)\n",
    "                elif (self.activationF == 'linear'):\n",
    "                    outs = self.linear(outs)\n",
    "                else:\n",
    "                    outs = self.tanh(outs)\n",
    "            self.X[i+1] = outs\n",
    "        pred = (np.argmax(self.X[-1],axis=1).T)\n",
    "        # print(pred)\n",
    "        return pred\n",
    "\n",
    "\n",
    "    def cross_entropy(self,y_pred,y):\n",
    "        cost = np.sum(y*np.log(y_pred))\n",
    "        return -1*cost/len(y)\n",
    "    \n",
    "    def score(self,test_x, test_y):\n",
    "        pred = self.predict(test_x)\n",
    "        predD = pred-test_y\n",
    "        po = np.where(predD==0)\n",
    "        crr = len(po[0])\n",
    "        return crr/test_x.shape[0]\n",
    "\n",
    "    def softmax(self,z):\n",
    "        z -= np.max(z)\n",
    "        y = np.exp(z)\n",
    "        return y / y.sum(axis=1,keepdims=True)\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        z = np.where(np.exp(-z)==np.inf,0,1/(1+np.exp(-z)))\n",
    "        return z\n",
    "\n",
    "    def sigmoidDiff(self,z):\n",
    "        return z*(1.0-z)\n",
    "\n",
    "    def linear(self,z):\n",
    "        return z\n",
    "\n",
    "    def linearDiff(self,z):\n",
    "        return 1\n",
    "\n",
    "    def tanh(self,z):\n",
    "        return np.tanh(z)\n",
    "\n",
    "    def tanhDiff(self,z):\n",
    "        return (1-(z**2))\n",
    "\n",
    "    def relu(self,z):\n",
    "        return np.where(z<0,0,z)\n",
    "\n",
    "    def reluDiff(self,z):\n",
    "        return np.where(z==0,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CcMBRAGrYwYD",
    "outputId": "653bef1f-7b7e-4f7f-b856-72a0bd06e62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training accuracy: 0.09914999999999996\n",
      "Epoch: 1 Training accuracy: 0.09863333333333335\n",
      "Epoch: 2 Training accuracy: 0.10441666666666671\n",
      "Epoch: 3 Training accuracy: 0.10441666666666671\n",
      "Epoch: 4 Training accuracy: 0.10441666666666671\n",
      "Epoch: 5 Training accuracy: 0.10441666666666671\n",
      "Epoch: 6 Training accuracy: 0.10441666666666671\n",
      "Epoch: 7 Training accuracy: 0.10441666666666671\n",
      "Epoch: 8 Training accuracy: 0.10441666666666671\n",
      "Epoch: 9 Training accuracy: 0.10441666666666671\n",
      "Epoch: 10 Training accuracy: 0.10441666666666671\n",
      "Epoch: 11 Training accuracy: 0.10441666666666671\n",
      "Epoch: 12 Training accuracy: 0.10441666666666671\n",
      "Epoch: 13 Training accuracy: 0.10441666666666671\n",
      "Epoch: 14 Training accuracy: 0.10441666666666671\n",
      "Epoch: 15 Training accuracy: 0.10441666666666671\n",
      "Epoch: 16 Training accuracy: 0.10441666666666671\n",
      "Epoch: 17 Training accuracy: 0.10441666666666671\n",
      "Epoch: 18 Training accuracy: 0.10441666666666671\n",
      "Epoch: 19 Training accuracy: 0.10441666666666671\n",
      "Epoch: 20 Training accuracy: 0.10441666666666671\n",
      "Epoch: 21 Training accuracy: 0.10441666666666671\n",
      "Epoch: 22 Training accuracy: 0.10441666666666671\n",
      "Epoch: 23 Training accuracy: 0.10441666666666671\n",
      "Epoch: 24 Training accuracy: 0.10441666666666671\n",
      "Epoch: 25 Training accuracy: 0.10441666666666671\n",
      "Epoch: 26 Training accuracy: 0.10441666666666671\n",
      "Epoch: 27 Training accuracy: 0.10441666666666671\n",
      "Epoch: 28 Training accuracy: 0.10441666666666671\n",
      "Epoch: 29 Training accuracy: 0.10441666666666671\n",
      "Epoch: 30 Training accuracy: 0.10441666666666671\n",
      "Epoch: 31 Training accuracy: 0.10441666666666671\n",
      "Epoch: 32 Training accuracy: 0.10441666666666671\n",
      "Epoch: 33 Training accuracy: 0.10441666666666671\n",
      "Epoch: 34 Training accuracy: 0.10441666666666671\n",
      "Epoch: 35 Training accuracy: 0.10441666666666671\n",
      "Epoch: 36 Training accuracy: 0.10441666666666671\n",
      "Epoch: 37 Training accuracy: 0.10441666666666671\n",
      "Epoch: 38 Training accuracy: 0.10441666666666671\n",
      "Epoch: 39 Training accuracy: 0.10441666666666671\n",
      "Epoch: 40 Training accuracy: 0.10441666666666671\n",
      "Epoch: 41 Training accuracy: 0.10441666666666671\n",
      "Epoch: 42 Training accuracy: 0.10441666666666671\n",
      "Epoch: 43 Training accuracy: 0.10441666666666671\n",
      "Epoch: 44 Training accuracy: 0.1515833333333333\n",
      "Epoch: 45 Training accuracy: 0.18706666666666671\n",
      "Epoch: 46 Training accuracy: 0.20066666666666666\n",
      "Epoch: 47 Training accuracy: 0.2051333333333334\n",
      "Epoch: 48 Training accuracy: 0.20273333333333332\n",
      "Epoch: 49 Training accuracy: 0.19343333333333335\n",
      "Epoch: 50 Training accuracy: 0.2340833333333333\n",
      "Epoch: 51 Training accuracy: 0.3091999999999999\n",
      "Epoch: 52 Training accuracy: 0.3301666666666667\n",
      "Epoch: 53 Training accuracy: 0.3432333333333333\n",
      "Epoch: 54 Training accuracy: 0.3516166666666667\n",
      "Epoch: 55 Training accuracy: 0.3559833333333333\n",
      "Epoch: 56 Training accuracy: 0.34735000000000005\n",
      "Epoch: 57 Training accuracy: 0.35660000000000003\n",
      "Epoch: 58 Training accuracy: 0.3603666666666667\n",
      "Epoch: 59 Training accuracy: 0.36339999999999995\n",
      "Epoch: 60 Training accuracy: 0.3659833333333333\n",
      "Epoch: 61 Training accuracy: 0.36858333333333326\n",
      "Epoch: 62 Training accuracy: 0.37006666666666665\n",
      "Epoch: 63 Training accuracy: 0.37095\n",
      "Epoch: 64 Training accuracy: 0.37073333333333336\n",
      "Epoch: 65 Training accuracy: 0.37559999999999993\n",
      "Epoch: 66 Training accuracy: 0.37678333333333336\n",
      "Epoch: 67 Training accuracy: 0.37763333333333327\n",
      "Epoch: 68 Training accuracy: 0.37921666666666665\n",
      "Epoch: 69 Training accuracy: 0.38011666666666666\n",
      "Epoch: 70 Training accuracy: 0.3841833333333333\n",
      "Epoch: 71 Training accuracy: 0.39165000000000005\n",
      "Epoch: 72 Training accuracy: 0.401\n",
      "Epoch: 73 Training accuracy: 0.4160166666666667\n",
      "Epoch: 74 Training accuracy: 0.4699333333333333\n",
      "Epoch: 75 Training accuracy: 0.5252333333333333\n",
      "Epoch: 76 Training accuracy: 0.5715666666666667\n",
      "Epoch: 77 Training accuracy: 0.59875\n",
      "Epoch: 78 Training accuracy: 0.6182833333333333\n",
      "Epoch: 79 Training accuracy: 0.6368333333333334\n",
      "Epoch: 80 Training accuracy: 0.6521333333333333\n",
      "Epoch: 81 Training accuracy: 0.6647\n",
      "Epoch: 82 Training accuracy: 0.6776166666666666\n",
      "Epoch: 83 Training accuracy: 0.6912666666666667\n",
      "Epoch: 84 Training accuracy: 0.7102666666666667\n",
      "Epoch: 85 Training accuracy: 0.7314\n",
      "Epoch: 86 Training accuracy: 0.7544\n",
      "Epoch: 87 Training accuracy: 0.7748833333333334\n",
      "Epoch: 88 Training accuracy: 0.7924833333333333\n",
      "Epoch: 89 Training accuracy: 0.81\n",
      "Epoch: 90 Training accuracy: 0.8313166666666667\n",
      "Epoch: 91 Training accuracy: 0.8512666666666666\n",
      "Epoch: 92 Training accuracy: 0.8602833333333333\n",
      "Epoch: 93 Training accuracy: 0.8675\n",
      "Epoch: 94 Training accuracy: 0.87345\n",
      "Epoch: 95 Training accuracy: 0.8779333333333333\n",
      "Epoch: 96 Training accuracy: 0.8822333333333333\n",
      "Epoch: 97 Training accuracy: 0.8863833333333333\n",
      "Epoch: 98 Training accuracy: 0.8898666666666667\n",
      "Epoch: 99 Training accuracy: 0.8934333333333333\n",
      "0.8954\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = Neural_Net(5,[28**2,256,128,64,10],'sigmoid',0.1)\n",
    "err = a.fit(train_x,train_y)\n",
    "sc = a.score(test_x,test_y)\n",
    "print(sc)\n",
    "\n",
    "plt.plot(np.arange(100),err)\n",
    "plt.title('Sigmoid')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Train Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_FhZ9VMsO35H"
   },
   "outputs": [],
   "source": [
    "dbfile = open('/content/gdrive/My Drive/ML/Assignment3/q1/mySigmoid', 'ab')\n",
    "pickle.dump(a, dbfile)                      \n",
    "dbfile.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IXwUV2ZsPA5O",
    "outputId": "c3a97589-9fb5-423b-96b6-6c616c8b22c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training accuracy: 0.09511666666666663\n",
      "Epoch: 1 Training accuracy: 0.10441666666666671\n",
      "Epoch: 2 Training accuracy: 0.10441666666666671\n",
      "Epoch: 3 Training accuracy: 0.10441666666666671\n",
      "Epoch: 4 Training accuracy: 0.10441666666666671\n",
      "Epoch: 5 Training accuracy: 0.10441666666666671\n",
      "Epoch: 6 Training accuracy: 0.10441666666666671\n",
      "Epoch: 7 Training accuracy: 0.10441666666666671\n",
      "Epoch: 8 Training accuracy: 0.37711666666666666\n",
      "Epoch: 9 Training accuracy: 0.8315833333333333\n",
      "Epoch: 10 Training accuracy: 0.9146166666666666\n",
      "Epoch: 11 Training accuracy: 0.9360166666666667\n",
      "Epoch: 12 Training accuracy: 0.94995\n",
      "Epoch: 13 Training accuracy: 0.9555333333333333\n",
      "Epoch: 14 Training accuracy: 0.9607\n",
      "Epoch: 15 Training accuracy: 0.9664833333333334\n",
      "Epoch: 16 Training accuracy: 0.9593666666666667\n",
      "Epoch: 17 Training accuracy: 0.9651\n",
      "Epoch: 18 Training accuracy: 0.9706333333333333\n",
      "Epoch: 19 Training accuracy: 0.9719833333333333\n",
      "Epoch: 20 Training accuracy: 0.9729\n",
      "Epoch: 21 Training accuracy: 0.9744166666666667\n",
      "Epoch: 22 Training accuracy: 0.9726833333333333\n",
      "Epoch: 23 Training accuracy: 0.9775\n",
      "Epoch: 24 Training accuracy: 0.9801666666666666\n",
      "Epoch: 25 Training accuracy: 0.9671333333333333\n",
      "Epoch: 26 Training accuracy: 0.9667\n",
      "Epoch: 27 Training accuracy: 0.9723166666666667\n",
      "Epoch: 28 Training accuracy: 0.9793833333333334\n",
      "Epoch: 29 Training accuracy: 0.9741666666666666\n",
      "Epoch: 30 Training accuracy: 0.9735666666666667\n",
      "Epoch: 31 Training accuracy: 0.9785666666666667\n",
      "Epoch: 32 Training accuracy: 0.9824166666666667\n",
      "Epoch: 33 Training accuracy: 0.9735166666666667\n",
      "Epoch: 34 Training accuracy: 0.9727333333333333\n",
      "Epoch: 35 Training accuracy: 0.9890666666666666\n",
      "Epoch: 36 Training accuracy: 0.99085\n",
      "Epoch: 37 Training accuracy: 0.9934666666666667\n",
      "Epoch: 38 Training accuracy: 0.9932166666666666\n",
      "Epoch: 39 Training accuracy: 0.9943\n",
      "Epoch: 40 Training accuracy: 0.9915333333333334\n",
      "Epoch: 41 Training accuracy: 0.99255\n",
      "Epoch: 42 Training accuracy: 0.99235\n",
      "Epoch: 43 Training accuracy: 0.9933\n",
      "Epoch: 44 Training accuracy: 0.9907166666666667\n",
      "Epoch: 45 Training accuracy: 0.9941\n",
      "Epoch: 46 Training accuracy: 0.9946666666666667\n",
      "Epoch: 47 Training accuracy: 0.9945666666666667\n",
      "Epoch: 48 Training accuracy: 0.9913333333333333\n",
      "Epoch: 49 Training accuracy: 0.9968\n",
      "Epoch: 50 Training accuracy: 0.9983\n",
      "Epoch: 51 Training accuracy: 0.9897666666666667\n",
      "Epoch: 52 Training accuracy: 0.98985\n",
      "Epoch: 53 Training accuracy: 0.99895\n",
      "Epoch: 54 Training accuracy: 0.9987666666666667\n",
      "Epoch: 55 Training accuracy: 0.9964666666666666\n",
      "Epoch: 56 Training accuracy: 0.9889333333333333\n",
      "Epoch: 57 Training accuracy: 0.9889833333333333\n",
      "Epoch: 58 Training accuracy: 0.9915333333333334\n",
      "Epoch: 59 Training accuracy: 0.9970833333333333\n",
      "Epoch: 60 Training accuracy: 0.9982833333333333\n",
      "Epoch: 61 Training accuracy: 0.9984833333333333\n",
      "Epoch: 62 Training accuracy: 0.9990666666666667\n",
      "Epoch: 63 Training accuracy: 0.9996666666666667\n",
      "Epoch: 64 Training accuracy: 0.9997833333333334\n",
      "Epoch: 65 Training accuracy: 0.99995\n",
      "Epoch: 66 Training accuracy: 0.9999666666666667\n",
      "Epoch: 67 Training accuracy: 0.9999666666666667\n",
      "Epoch: 68 Training accuracy: 1.0\n",
      "Epoch: 69 Training accuracy: 1.0\n",
      "Epoch: 70 Training accuracy: 1.0\n",
      "Epoch: 71 Training accuracy: 1.0\n",
      "Epoch: 72 Training accuracy: 1.0\n",
      "Epoch: 73 Training accuracy: 1.0\n",
      "Epoch: 74 Training accuracy: 1.0\n",
      "Epoch: 75 Training accuracy: 1.0\n",
      "Epoch: 76 Training accuracy: 1.0\n",
      "Epoch: 77 Training accuracy: 1.0\n",
      "Epoch: 78 Training accuracy: 1.0\n",
      "Epoch: 79 Training accuracy: 1.0\n",
      "Epoch: 80 Training accuracy: 1.0\n",
      "Epoch: 81 Training accuracy: 1.0\n",
      "Epoch: 82 Training accuracy: 1.0\n",
      "Epoch: 83 Training accuracy: 1.0\n",
      "Epoch: 84 Training accuracy: 1.0\n",
      "Epoch: 85 Training accuracy: 1.0\n",
      "Epoch: 86 Training accuracy: 1.0\n",
      "Epoch: 87 Training accuracy: 1.0\n",
      "Epoch: 88 Training accuracy: 1.0\n",
      "Epoch: 89 Training accuracy: 1.0\n",
      "Epoch: 90 Training accuracy: 1.0\n",
      "Epoch: 91 Training accuracy: 1.0\n",
      "Epoch: 92 Training accuracy: 1.0\n",
      "Epoch: 93 Training accuracy: 1.0\n",
      "Epoch: 94 Training accuracy: 1.0\n",
      "Epoch: 95 Training accuracy: 1.0\n",
      "Epoch: 96 Training accuracy: 1.0\n",
      "Epoch: 97 Training accuracy: 1.0\n",
      "Epoch: 98 Training accuracy: 1.0\n",
      "Epoch: 99 Training accuracy: 1.0\n",
      "0.9811\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-28e81965c73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdbfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m     return gca().plot(\n\u001b[1;32m   2794\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2795\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (100,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8CWpCYMvSU0YfElq4n8BzPZcum6w2goAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = Neural_Net(5,[28**2,256,128,64,10],'relu',0.1)\n",
    "err = b.fit(train_x,train_y,epochs=100)\n",
    "sc = b.score(test_x,test_y)\n",
    "print(sc)\n",
    "dbfile = open('/content/gdrive/My Drive/ML/Assignment3/q1/myRelu', 'ab')\n",
    "pickle.dump(b, dbfile)                      \n",
    "dbfile.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "kmDe24cvTTLc",
    "outputId": "a6937339-9f58-4730-e8e4-2b681a174f35"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(100),err)\n",
    "plt.title('Relu')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Train Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "v4o4a0JjPn6X",
    "outputId": "66663dcc-7d83-47bf-bcc5-e2c462af8516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training accuracy: 0.09878333333333333\n",
      "Epoch: 1 Training accuracy: 0.10441666666666671\n",
      "Epoch: 2 Training accuracy: 0.10441666666666671\n",
      "Epoch: 3 Training accuracy: 0.10441666666666671\n",
      "Epoch: 4 Training accuracy: 0.30935\n",
      "Epoch: 5 Training accuracy: 0.6206833333333334\n",
      "Epoch: 6 Training accuracy: 0.74735\n",
      "Epoch: 7 Training accuracy: 0.8157166666666666\n",
      "Epoch: 8 Training accuracy: 0.8533666666666667\n",
      "Epoch: 9 Training accuracy: 0.85535\n",
      "Epoch: 10 Training accuracy: 0.85665\n",
      "Epoch: 11 Training accuracy: 0.8574666666666667\n",
      "Epoch: 12 Training accuracy: 0.8578666666666667\n",
      "Epoch: 13 Training accuracy: 0.8589833333333333\n",
      "Epoch: 14 Training accuracy: 0.8779166666666667\n",
      "Epoch: 15 Training accuracy: 0.8831833333333333\n",
      "Epoch: 16 Training accuracy: 0.8834\n",
      "Epoch: 17 Training accuracy: 0.8837333333333334\n",
      "Epoch: 18 Training accuracy: 0.8838166666666667\n",
      "Epoch: 19 Training accuracy: 0.8837166666666667\n",
      "Epoch: 20 Training accuracy: 0.8841166666666667\n",
      "Epoch: 21 Training accuracy: 0.8846333333333334\n",
      "Epoch: 22 Training accuracy: 0.8850333333333333\n",
      "Epoch: 23 Training accuracy: 0.8852333333333333\n",
      "Epoch: 24 Training accuracy: 0.8854833333333333\n",
      "Epoch: 25 Training accuracy: 0.8856666666666667\n",
      "Epoch: 26 Training accuracy: 0.8857833333333334\n",
      "Epoch: 27 Training accuracy: 0.88605\n",
      "Epoch: 28 Training accuracy: 0.88625\n",
      "Epoch: 29 Training accuracy: 0.88645\n",
      "Epoch: 30 Training accuracy: 0.8864666666666666\n",
      "Epoch: 31 Training accuracy: 0.8866166666666667\n",
      "Epoch: 32 Training accuracy: 0.8871333333333333\n",
      "Epoch: 33 Training accuracy: 0.8889666666666667\n",
      "Epoch: 34 Training accuracy: 0.8968166666666667\n",
      "Epoch: 35 Training accuracy: 0.8985166666666666\n",
      "Epoch: 36 Training accuracy: 0.8992333333333333\n",
      "Epoch: 37 Training accuracy: 0.8996166666666666\n",
      "Epoch: 38 Training accuracy: 0.9004\n",
      "Epoch: 39 Training accuracy: 0.9011833333333333\n",
      "Epoch: 40 Training accuracy: 0.9013666666666666\n",
      "Epoch: 41 Training accuracy: 0.9018166666666667\n",
      "Epoch: 42 Training accuracy: 0.9019833333333334\n",
      "Epoch: 43 Training accuracy: 0.9023166666666667\n",
      "Epoch: 44 Training accuracy: 0.9024666666666666\n",
      "Epoch: 45 Training accuracy: 0.9027833333333334\n",
      "Epoch: 46 Training accuracy: 0.9030166666666667\n",
      "Epoch: 47 Training accuracy: 0.9032666666666667\n",
      "Epoch: 48 Training accuracy: 0.90345\n",
      "Epoch: 49 Training accuracy: 0.9034166666666666\n",
      "Epoch: 50 Training accuracy: 0.9036833333333333\n",
      "Epoch: 51 Training accuracy: 0.9038833333333334\n",
      "Epoch: 52 Training accuracy: 0.9039166666666667\n",
      "Epoch: 53 Training accuracy: 0.9040666666666667\n",
      "Epoch: 54 Training accuracy: 0.9041\n",
      "Epoch: 55 Training accuracy: 0.90415\n",
      "Epoch: 56 Training accuracy: 0.9043166666666667\n",
      "Epoch: 57 Training accuracy: 0.9044166666666666\n",
      "Epoch: 58 Training accuracy: 0.9045\n",
      "Epoch: 59 Training accuracy: 0.9046333333333333\n",
      "Epoch: 60 Training accuracy: 0.90465\n",
      "Epoch: 61 Training accuracy: 0.9047833333333334\n",
      "Epoch: 62 Training accuracy: 0.9049\n",
      "Epoch: 63 Training accuracy: 0.90495\n",
      "Epoch: 64 Training accuracy: 0.9049666666666667\n",
      "Epoch: 65 Training accuracy: 0.90505\n",
      "Epoch: 66 Training accuracy: 0.9050666666666667\n",
      "Epoch: 67 Training accuracy: 0.9051666666666667\n",
      "Epoch: 68 Training accuracy: 0.9053166666666667\n",
      "Epoch: 69 Training accuracy: 0.9054833333333333\n",
      "Epoch: 70 Training accuracy: 0.90555\n",
      "Epoch: 71 Training accuracy: 0.9055333333333333\n",
      "Epoch: 72 Training accuracy: 0.9056666666666666\n",
      "Epoch: 73 Training accuracy: 0.9057333333333333\n",
      "Epoch: 74 Training accuracy: 0.9056666666666666\n",
      "Epoch: 75 Training accuracy: 0.9057166666666666\n",
      "Epoch: 76 Training accuracy: 0.9058166666666667\n",
      "Epoch: 77 Training accuracy: 0.9059\n",
      "Epoch: 78 Training accuracy: 0.9059333333333334\n",
      "Epoch: 79 Training accuracy: 0.9059333333333334\n",
      "Epoch: 80 Training accuracy: 0.9059333333333334\n",
      "Epoch: 81 Training accuracy: 0.9059166666666667\n",
      "Epoch: 82 Training accuracy: 0.9059\n",
      "Epoch: 83 Training accuracy: 0.9060666666666667\n",
      "Epoch: 84 Training accuracy: 0.9059666666666667\n",
      "Epoch: 85 Training accuracy: 0.90605\n",
      "Epoch: 86 Training accuracy: 0.9060333333333334\n",
      "Epoch: 87 Training accuracy: 0.906\n",
      "Epoch: 88 Training accuracy: 0.9060166666666667\n",
      "Epoch: 89 Training accuracy: 0.9060666666666667\n",
      "Epoch: 90 Training accuracy: 0.9060666666666667\n",
      "Epoch: 91 Training accuracy: 0.9060833333333334\n",
      "Epoch: 92 Training accuracy: 0.9060666666666667\n",
      "Epoch: 93 Training accuracy: 0.9060833333333334\n",
      "Epoch: 94 Training accuracy: 0.9060166666666667\n",
      "Epoch: 95 Training accuracy: 0.9060166666666667\n",
      "Epoch: 96 Training accuracy: 0.906\n",
      "Epoch: 97 Training accuracy: 0.90595\n",
      "Epoch: 98 Training accuracy: 0.9059166666666667\n",
      "Epoch: 99 Training accuracy: 0.9059666666666667\n",
      "0.9007\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = Neural_Net(5,[28**2,256,128,64,10],'linear',0.1)\n",
    "err = c.fit(train_x,train_y,epochs=100)\n",
    "sc = c.score(test_x,test_y)\n",
    "print(sc)\n",
    "dbfile = open('/content/gdrive/My Drive/ML/Assignment3/q1/myLinear', 'ab')\n",
    "pickle.dump(c, dbfile)                      \n",
    "dbfile.close()\n",
    "\n",
    "plt.plot(np.arange(100),err)\n",
    "plt.title('Linear')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Train Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Qu1jyjIiP2wP",
    "outputId": "426c145d-2bfb-4b43-fda5-37ea19f5fca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training accuracy: 0.08245000000000002\n",
      "Epoch: 1 Training accuracy: 0.10441666666666671\n",
      "Epoch: 2 Training accuracy: 0.10441666666666671\n",
      "Epoch: 3 Training accuracy: 0.10441666666666671\n",
      "Epoch: 4 Training accuracy: 0.2716166666666666\n",
      "Epoch: 5 Training accuracy: 0.5725166666666667\n",
      "Epoch: 6 Training accuracy: 0.7680666666666667\n",
      "Epoch: 7 Training accuracy: 0.8573333333333333\n",
      "Epoch: 8 Training accuracy: 0.8700166666666667\n",
      "Epoch: 9 Training accuracy: 0.87835\n",
      "Epoch: 10 Training accuracy: 0.8931333333333333\n",
      "Epoch: 11 Training accuracy: 0.8982166666666667\n",
      "Epoch: 12 Training accuracy: 0.9001166666666667\n",
      "Epoch: 13 Training accuracy: 0.9026166666666666\n",
      "Epoch: 14 Training accuracy: 0.90515\n",
      "Epoch: 15 Training accuracy: 0.9092166666666667\n",
      "Epoch: 16 Training accuracy: 0.9158833333333334\n",
      "Epoch: 17 Training accuracy: 0.9214833333333333\n",
      "Epoch: 18 Training accuracy: 0.9265666666666666\n",
      "Epoch: 19 Training accuracy: 0.9322\n",
      "Epoch: 20 Training accuracy: 0.9358166666666666\n",
      "Epoch: 21 Training accuracy: 0.938\n",
      "Epoch: 22 Training accuracy: 0.9400166666666666\n",
      "Epoch: 23 Training accuracy: 0.9416833333333333\n",
      "Epoch: 24 Training accuracy: 0.9432\n",
      "Epoch: 25 Training accuracy: 0.9447333333333333\n",
      "Epoch: 26 Training accuracy: 0.9462333333333334\n",
      "Epoch: 27 Training accuracy: 0.9476166666666667\n",
      "Epoch: 28 Training accuracy: 0.9492166666666667\n",
      "Epoch: 29 Training accuracy: 0.9502666666666667\n",
      "Epoch: 30 Training accuracy: 0.9512666666666667\n",
      "Epoch: 31 Training accuracy: 0.9519\n",
      "Epoch: 32 Training accuracy: 0.9525833333333333\n",
      "Epoch: 33 Training accuracy: 0.9533\n",
      "Epoch: 34 Training accuracy: 0.95455\n",
      "Epoch: 35 Training accuracy: 0.9554833333333334\n",
      "Epoch: 36 Training accuracy: 0.9563\n",
      "Epoch: 37 Training accuracy: 0.95745\n",
      "Epoch: 38 Training accuracy: 0.95875\n",
      "Epoch: 39 Training accuracy: 0.9598833333333333\n",
      "Epoch: 40 Training accuracy: 0.9614\n",
      "Epoch: 41 Training accuracy: 0.9626666666666667\n",
      "Epoch: 42 Training accuracy: 0.9639\n",
      "Epoch: 43 Training accuracy: 0.9650666666666666\n",
      "Epoch: 44 Training accuracy: 0.9659666666666666\n",
      "Epoch: 45 Training accuracy: 0.9672833333333334\n",
      "Epoch: 46 Training accuracy: 0.9683166666666667\n",
      "Epoch: 47 Training accuracy: 0.9692166666666666\n",
      "Epoch: 48 Training accuracy: 0.9702\n",
      "Epoch: 49 Training accuracy: 0.97075\n",
      "Epoch: 50 Training accuracy: 0.9714666666666667\n",
      "Epoch: 51 Training accuracy: 0.9722\n",
      "Epoch: 52 Training accuracy: 0.9725833333333334\n",
      "Epoch: 53 Training accuracy: 0.9731666666666666\n",
      "Epoch: 54 Training accuracy: 0.9736\n",
      "Epoch: 55 Training accuracy: 0.9743\n",
      "Epoch: 56 Training accuracy: 0.97505\n",
      "Epoch: 57 Training accuracy: 0.9758166666666667\n",
      "Epoch: 58 Training accuracy: 0.9763666666666667\n",
      "Epoch: 59 Training accuracy: 0.9768166666666667\n",
      "Epoch: 60 Training accuracy: 0.9775833333333334\n",
      "Epoch: 61 Training accuracy: 0.9781166666666666\n",
      "Epoch: 62 Training accuracy: 0.9786333333333334\n",
      "Epoch: 63 Training accuracy: 0.9791\n",
      "Epoch: 64 Training accuracy: 0.9797666666666667\n",
      "Epoch: 65 Training accuracy: 0.9803166666666666\n",
      "Epoch: 66 Training accuracy: 0.9805833333333334\n",
      "Epoch: 67 Training accuracy: 0.9809333333333333\n",
      "Epoch: 68 Training accuracy: 0.9811666666666666\n",
      "Epoch: 69 Training accuracy: 0.9816166666666667\n",
      "Epoch: 70 Training accuracy: 0.9821166666666666\n",
      "Epoch: 71 Training accuracy: 0.9827333333333333\n",
      "Epoch: 72 Training accuracy: 0.9833666666666666\n",
      "Epoch: 73 Training accuracy: 0.9839833333333333\n",
      "Epoch: 74 Training accuracy: 0.9844666666666667\n",
      "Epoch: 75 Training accuracy: 0.9850833333333333\n",
      "Epoch: 76 Training accuracy: 0.9857333333333334\n",
      "Epoch: 77 Training accuracy: 0.9863666666666666\n",
      "Epoch: 78 Training accuracy: 0.9868833333333333\n",
      "Epoch: 79 Training accuracy: 0.98745\n",
      "Epoch: 80 Training accuracy: 0.98795\n",
      "Epoch: 81 Training accuracy: 0.9884\n",
      "Epoch: 82 Training accuracy: 0.9889333333333333\n",
      "Epoch: 83 Training accuracy: 0.9893833333333333\n",
      "Epoch: 84 Training accuracy: 0.9897166666666667\n",
      "Epoch: 85 Training accuracy: 0.9902166666666666\n",
      "Epoch: 86 Training accuracy: 0.9907166666666667\n",
      "Epoch: 87 Training accuracy: 0.9910666666666667\n",
      "Epoch: 88 Training accuracy: 0.9916\n",
      "Epoch: 89 Training accuracy: 0.9921333333333333\n",
      "Epoch: 90 Training accuracy: 0.9924833333333334\n",
      "Epoch: 91 Training accuracy: 0.9928333333333333\n",
      "Epoch: 92 Training accuracy: 0.9931666666666666\n",
      "Epoch: 93 Training accuracy: 0.99355\n",
      "Epoch: 94 Training accuracy: 0.99385\n",
      "Epoch: 95 Training accuracy: 0.9941333333333333\n",
      "Epoch: 96 Training accuracy: 0.9944666666666667\n",
      "Epoch: 97 Training accuracy: 0.9947166666666667\n",
      "Epoch: 98 Training accuracy: 0.995\n",
      "Epoch: 99 Training accuracy: 0.9951833333333333\n",
      "0.9665\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = Neural_Net(5,[28**2,256,128,64,10],'tanh',0.1)\n",
    "err = d.fit(train_x,train_y,epochs=100)\n",
    "sc = d.score(test_x,test_y)\n",
    "print(sc)\n",
    "dbfile = open('/content/gdrive/My Drive/ML/Assignment3/q1/myTanh', 'ab')\n",
    "pickle.dump(d, dbfile)                      \n",
    "dbfile.close() \n",
    "\n",
    "plt.plot(np.arange(100),err)\n",
    "plt.title('Tanh')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Train Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3eP5WsFG4co"
   },
   "source": [
    "RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T17:05:38.464635Z",
     "start_time": "2019-11-11T17:00:56.180277Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "B75nmVe_7r04",
    "outputId": "4006c342-deef-45c4-c151-71d713bc9ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.47844288\n",
      "Iteration 2, loss = 0.15156598\n",
      "Iteration 3, loss = 0.10907833\n",
      "Iteration 4, loss = 0.08467951\n",
      "Iteration 5, loss = 0.07181850\n",
      "Iteration 6, loss = 0.05906530\n",
      "Iteration 7, loss = 0.05155210\n",
      "Iteration 8, loss = 0.04643946\n",
      "Iteration 9, loss = 0.04179414\n",
      "Iteration 10, loss = 0.03655987\n",
      "Iteration 11, loss = 0.03117815\n",
      "Iteration 12, loss = 0.02966068\n",
      "Iteration 13, loss = 0.02553826\n",
      "Iteration 14, loss = 0.02293330\n",
      "Iteration 15, loss = 0.02253987\n",
      "Iteration 16, loss = 0.02088813\n",
      "Iteration 17, loss = 0.01786116\n",
      "Iteration 18, loss = 0.01583656\n",
      "Iteration 19, loss = 0.01677145\n",
      "Iteration 20, loss = 0.01751674\n",
      "Iteration 21, loss = 0.01402298\n",
      "Iteration 22, loss = 0.01406891\n",
      "Iteration 23, loss = 0.01341955\n",
      "Iteration 24, loss = 0.01328090\n",
      "Iteration 25, loss = 0.01196029\n",
      "Iteration 26, loss = 0.00801536\n",
      "Iteration 27, loss = 0.00645983\n",
      "Iteration 28, loss = 0.00512045\n",
      "Iteration 29, loss = 0.00994121\n",
      "Iteration 30, loss = 0.00968972\n",
      "Iteration 31, loss = 0.00568104\n",
      "Iteration 32, loss = 0.00665596\n",
      "Iteration 33, loss = 0.00386820\n",
      "Iteration 34, loss = 0.00440117\n",
      "Iteration 35, loss = 0.00683257\n",
      "Iteration 36, loss = 0.00845155\n",
      "Iteration 37, loss = 0.00458386\n",
      "Iteration 38, loss = 0.00767582\n",
      "Iteration 39, loss = 0.00762877\n",
      "Iteration 40, loss = 0.01013106\n",
      "Iteration 41, loss = 0.00930827\n",
      "Iteration 42, loss = 0.01123002\n",
      "Iteration 43, loss = 0.00887125\n",
      "Iteration 44, loss = 0.00944030\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training accuracy: 0.9979166666666667\n",
      "Testing accuracy: 0.981\n"
     ]
    }
   ],
   "source": [
    "reg1 = MLPClassifier(hidden_layer_sizes=(256, 128, 64), solver='sgd',learning_rate='constant', learning_rate_init=0.1, batch_size=128, max_iter=100,verbose=True)\n",
    "reg1.fit(train_x, train_y)\n",
    "t = reg1.score(train_x,train_y)\n",
    "tt = reg1.score(test_x, test_y)\n",
    "print('Training accuracy:',t)\n",
    "print('Testing accuracy:',tt)\n",
    "dbfile = open('/content/gdrive/My Drive/ML/Assignment3/q1/sklearn_relu', 'ab')\n",
    "pickle.dump(reg1, dbfile)                      \n",
    "dbfile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhbW2ZwSG7Mt"
   },
   "source": [
    "Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T17:13:46.592666Z",
     "start_time": "2019-11-11T17:06:12.360644Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4eujFCDB7r09",
    "outputId": "b28e906d-79b1-4913-8f26-5131fd51497b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.44368270\n",
      "Iteration 2, loss = 0.31369635\n",
      "Iteration 3, loss = 0.30346944\n",
      "Iteration 4, loss = 0.29738647\n",
      "Iteration 5, loss = 0.29167862\n",
      "Iteration 6, loss = 0.28888978\n",
      "Iteration 7, loss = 0.28577081\n",
      "Iteration 8, loss = 0.28418442\n",
      "Iteration 9, loss = 0.28256424\n",
      "Iteration 10, loss = 0.28033295\n",
      "Iteration 11, loss = 0.27986093\n",
      "Iteration 12, loss = 0.27796524\n",
      "Iteration 13, loss = 0.27805527\n",
      "Iteration 14, loss = 0.27641759\n",
      "Iteration 15, loss = 0.27532951\n",
      "Iteration 16, loss = 0.27576722\n",
      "Iteration 17, loss = 0.27344103\n",
      "Iteration 18, loss = 0.27491846\n",
      "Iteration 19, loss = 0.27167537\n",
      "Iteration 20, loss = 0.27225863\n",
      "Iteration 21, loss = 0.27220610\n",
      "Iteration 22, loss = 0.27104748\n",
      "Iteration 23, loss = 0.27000758\n",
      "Iteration 24, loss = 0.27004663\n",
      "Iteration 25, loss = 0.27159461\n",
      "Iteration 26, loss = 0.27051809\n",
      "Iteration 27, loss = 0.26760979\n",
      "Iteration 28, loss = 0.26998177\n",
      "Iteration 29, loss = 0.26800299\n",
      "Iteration 30, loss = 0.26792068\n",
      "Iteration 31, loss = 0.26748275\n",
      "Iteration 32, loss = 0.26705521\n",
      "Iteration 33, loss = 0.26877278\n",
      "Iteration 34, loss = 0.26755973\n",
      "Iteration 35, loss = 0.26833128\n",
      "Iteration 36, loss = 0.26709075\n",
      "Iteration 37, loss = 0.26690256\n",
      "Iteration 38, loss = 0.26489452\n",
      "Iteration 39, loss = 0.26626128\n",
      "Iteration 40, loss = 0.26512050\n",
      "Iteration 41, loss = 0.26536439\n",
      "Iteration 42, loss = 0.26526978\n",
      "Iteration 43, loss = 0.26525462\n",
      "Iteration 44, loss = 0.26505141\n",
      "Iteration 45, loss = 0.26466061\n",
      "Iteration 46, loss = 0.26486136\n",
      "Iteration 47, loss = 0.26419286\n",
      "Iteration 48, loss = 0.26447773\n",
      "Iteration 49, loss = 0.26305083\n",
      "Iteration 50, loss = 0.26386284\n",
      "Iteration 51, loss = 0.26210379\n",
      "Iteration 52, loss = 0.26299989\n",
      "Iteration 53, loss = 0.26383094\n",
      "Iteration 54, loss = 0.26138122\n",
      "Iteration 55, loss = 0.26327042\n",
      "Iteration 56, loss = 0.26322056\n",
      "Iteration 57, loss = 0.26214509\n",
      "Iteration 58, loss = 0.26229414\n",
      "Iteration 59, loss = 0.26223441\n",
      "Iteration 60, loss = 0.26179128\n",
      "Iteration 61, loss = 0.26167760\n",
      "Iteration 62, loss = 0.26186357\n",
      "Iteration 63, loss = 0.26232654\n",
      "Iteration 64, loss = 0.26060907\n",
      "Iteration 65, loss = 0.26258361\n",
      "Iteration 66, loss = 0.26308240\n",
      "Iteration 67, loss = 0.26090365\n",
      "Iteration 68, loss = 0.26067242\n",
      "Iteration 69, loss = 0.26154046\n",
      "Iteration 70, loss = 0.26063526\n",
      "Iteration 71, loss = 0.26214936\n",
      "Iteration 72, loss = 0.25943330\n",
      "Iteration 73, loss = 0.26211603\n",
      "Iteration 74, loss = 0.26151128\n",
      "Iteration 75, loss = 0.26045243\n",
      "Iteration 76, loss = 0.25929950\n",
      "Iteration 77, loss = 0.25998791\n",
      "Iteration 78, loss = 0.26064859\n",
      "Iteration 79, loss = 0.25886875\n",
      "Iteration 80, loss = 0.26149755\n",
      "Iteration 81, loss = 0.25865580\n",
      "Iteration 82, loss = 0.25974229\n",
      "Iteration 83, loss = 0.26185056\n",
      "Iteration 84, loss = 0.25887161\n",
      "Iteration 85, loss = 0.26054128\n",
      "Iteration 86, loss = 0.26089411\n",
      "Iteration 87, loss = 0.26123949\n",
      "Iteration 88, loss = 0.25856016\n",
      "Iteration 89, loss = 0.25815005\n",
      "Iteration 90, loss = 0.26044960\n",
      "Iteration 91, loss = 0.26009917\n",
      "Iteration 92, loss = 0.25896346\n",
      "Iteration 93, loss = 0.25922072\n",
      "Iteration 94, loss = 0.25740836\n",
      "Iteration 95, loss = 0.25952220\n",
      "Iteration 96, loss = 0.25880102\n",
      "Iteration 97, loss = 0.25982418\n",
      "Iteration 98, loss = 0.25957662\n",
      "Iteration 99, loss = 0.25893019\n",
      "Iteration 100, loss = 0.25887456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.93005\n",
      "Testing accuracy: 0.919\n"
     ]
    }
   ],
   "source": [
    "reg2 = MLPClassifier(hidden_layer_sizes=(256, 128, 64), solver='sgd', activation='identity',learning_rate='constant', verbose=True , learning_rate_init=0.1, batch_size=128, max_iter=100)\n",
    "reg2.fit(train_x, train_y)\n",
    "t = reg2.score(train_x,train_y)\n",
    "tt = reg2.score(test_x, test_y)\n",
    "print('Training accuracy:',t)\n",
    "print('Testing accuracy:',tt)\n",
    "dbfile = open('/content/gdrive/My Drive/ML/Assignment3/q1/sklearn_lin', 'ab')\n",
    "pickle.dump(reg2, dbfile)                      \n",
    "dbfile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dT_P_zQBG9i8"
   },
   "source": [
    "Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T17:21:33.615428Z",
     "start_time": "2019-11-11T17:13:46.778898Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dOKkftyC7r1C",
    "outputId": "69403104-1d22-45dd-938e-d3ac89012961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.30826223\n",
      "Iteration 2, loss = 2.30363661\n",
      "Iteration 3, loss = 2.30324459\n",
      "Iteration 4, loss = 2.30314180\n",
      "Iteration 5, loss = 2.30314923\n",
      "Iteration 6, loss = 2.30302231\n",
      "Iteration 7, loss = 2.30321540\n",
      "Iteration 8, loss = 2.30303119\n",
      "Iteration 9, loss = 2.30301509\n",
      "Iteration 10, loss = 2.30267998\n",
      "Iteration 11, loss = 2.30278434\n",
      "Iteration 12, loss = 2.30268902\n",
      "Iteration 13, loss = 2.30244630\n",
      "Iteration 14, loss = 2.30195891\n",
      "Iteration 15, loss = 2.30023156\n",
      "Iteration 16, loss = 2.22814598\n",
      "Iteration 17, loss = 1.72253803\n",
      "Iteration 18, loss = 1.54000104\n",
      "Iteration 19, loss = 1.48857296\n",
      "Iteration 20, loss = 1.44241642\n",
      "Iteration 21, loss = 1.14366334\n",
      "Iteration 22, loss = 0.94602274\n",
      "Iteration 23, loss = 0.84055564\n",
      "Iteration 24, loss = 0.68484890\n",
      "Iteration 25, loss = 0.57881125\n",
      "Iteration 26, loss = 0.54036614\n",
      "Iteration 27, loss = 0.50895201\n",
      "Iteration 28, loss = 0.46746202\n",
      "Iteration 29, loss = 0.43492602\n",
      "Iteration 30, loss = 0.41229156\n",
      "Iteration 31, loss = 0.38779403\n",
      "Iteration 32, loss = 0.35698957\n",
      "Iteration 33, loss = 0.32908440\n",
      "Iteration 34, loss = 0.30631466\n",
      "Iteration 35, loss = 0.29135801\n",
      "Iteration 36, loss = 0.28125258\n",
      "Iteration 37, loss = 0.27271411\n",
      "Iteration 38, loss = 0.26501218\n",
      "Iteration 39, loss = 0.25842037\n",
      "Iteration 40, loss = 0.25422435\n",
      "Iteration 41, loss = 0.24883826\n",
      "Iteration 42, loss = 0.24396573\n",
      "Iteration 43, loss = 0.24035370\n",
      "Iteration 44, loss = 0.23424683\n",
      "Iteration 45, loss = 0.23103563\n",
      "Iteration 46, loss = 0.22785659\n",
      "Iteration 47, loss = 0.22337216\n",
      "Iteration 48, loss = 0.22064933\n",
      "Iteration 49, loss = 0.21647286\n",
      "Iteration 50, loss = 0.21246535\n",
      "Iteration 51, loss = 0.20925065\n",
      "Iteration 52, loss = 0.20562815\n",
      "Iteration 53, loss = 0.20164416\n",
      "Iteration 54, loss = 0.19668153\n",
      "Iteration 55, loss = 0.19281149\n",
      "Iteration 56, loss = 0.19041095\n",
      "Iteration 57, loss = 0.18522993\n",
      "Iteration 58, loss = 0.18152002\n",
      "Iteration 59, loss = 0.17782814\n",
      "Iteration 60, loss = 0.17486981\n",
      "Iteration 61, loss = 0.17134846\n",
      "Iteration 62, loss = 0.16819137\n",
      "Iteration 63, loss = 0.16506599\n",
      "Iteration 64, loss = 0.16157544\n",
      "Iteration 65, loss = 0.15781815\n",
      "Iteration 66, loss = 0.15471135\n",
      "Iteration 67, loss = 0.15180513\n",
      "Iteration 68, loss = 0.14952506\n",
      "Iteration 69, loss = 0.14712598\n",
      "Iteration 70, loss = 0.14384326\n",
      "Iteration 71, loss = 0.14155325\n",
      "Iteration 72, loss = 0.13947559\n",
      "Iteration 73, loss = 0.13706984\n",
      "Iteration 74, loss = 0.13410102\n",
      "Iteration 75, loss = 0.13162645\n",
      "Iteration 76, loss = 0.12869984\n",
      "Iteration 77, loss = 0.12664130\n",
      "Iteration 78, loss = 0.12482904\n",
      "Iteration 79, loss = 0.12230528\n",
      "Iteration 80, loss = 0.12120777\n",
      "Iteration 81, loss = 0.11779591\n",
      "Iteration 82, loss = 0.11677776\n",
      "Iteration 83, loss = 0.11447406\n",
      "Iteration 84, loss = 0.11303532\n",
      "Iteration 85, loss = 0.11011899\n",
      "Iteration 86, loss = 0.10845895\n",
      "Iteration 87, loss = 0.10751909\n",
      "Iteration 88, loss = 0.10557845\n",
      "Iteration 89, loss = 0.10387519\n",
      "Iteration 90, loss = 0.10251953\n",
      "Iteration 91, loss = 0.10051802\n",
      "Iteration 92, loss = 0.09914223\n",
      "Iteration 93, loss = 0.09845824\n",
      "Iteration 94, loss = 0.09614714\n",
      "Iteration 95, loss = 0.09549500\n",
      "Iteration 96, loss = 0.09403873\n",
      "Iteration 97, loss = 0.09236043\n",
      "Iteration 98, loss = 0.09126738\n",
      "Iteration 99, loss = 0.09006490\n",
      "Iteration 100, loss = 0.08910962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9760666666666666\n",
      "Testing accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "reg3 = MLPClassifier(hidden_layer_sizes=(256, 128, 64), verbose= True ,activation='logistic',learning_rate='constant', learning_rate_init=0.1, batch_size=128, max_iter=100, solver='sgd')\n",
    "reg3.fit(train_x, train_y)\n",
    "t = reg3.score(train_x,train_y)\n",
    "tt = reg3.score(test_x, test_y)\n",
    "print('Training accuracy:',t)\n",
    "print('Testing accuracy:',tt)\n",
    "dbfile = open('/content/gdrive/My Drive/ML/Assignment3/q1/sklearn_logistic', 'ab')\n",
    "pickle.dump(reg3, dbfile)                      \n",
    "dbfile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VLgjh61KHGuO"
   },
   "source": [
    "Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T17:26:36.876970Z",
     "start_time": "2019-11-11T17:21:33.725276Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "id": "0WkSRZnh7r1H",
    "outputId": "ccb410d6-1e00-4b4f-f505-784baec2be99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.41597922\n",
      "Iteration 2, loss = 0.21686119\n",
      "Iteration 3, loss = 0.17002546\n",
      "Iteration 4, loss = 0.14301172\n",
      "Iteration 5, loss = 0.12472952\n",
      "Iteration 6, loss = 0.11073870\n",
      "Iteration 7, loss = 0.10183973\n",
      "Iteration 8, loss = 0.09198013\n",
      "Iteration 9, loss = 0.08271423\n",
      "Iteration 10, loss = 0.07501413\n",
      "Iteration 11, loss = 0.06968924\n",
      "Iteration 12, loss = 0.06230268\n",
      "Iteration 13, loss = 0.05731446\n",
      "Iteration 14, loss = 0.05244455\n",
      "Iteration 15, loss = 0.05063450\n",
      "Iteration 16, loss = 0.04443693\n",
      "Iteration 17, loss = 0.04291616\n",
      "Iteration 18, loss = 0.03912852\n",
      "Iteration 19, loss = 0.03448261\n",
      "Iteration 20, loss = 0.03163394\n",
      "Iteration 21, loss = 0.03032716\n",
      "Iteration 22, loss = 0.02732701\n",
      "Iteration 23, loss = 0.02368234\n",
      "Iteration 24, loss = 0.02394295\n",
      "Iteration 25, loss = 0.02086798\n",
      "Iteration 26, loss = 0.01975023\n",
      "Iteration 27, loss = 0.01812395\n",
      "Iteration 28, loss = 0.01631443\n",
      "Iteration 29, loss = 0.01363775\n",
      "Iteration 30, loss = 0.01321733\n",
      "Iteration 31, loss = 0.01149995\n",
      "Iteration 32, loss = 0.00914711\n",
      "Iteration 33, loss = 0.00764363\n",
      "Iteration 34, loss = 0.00625231\n",
      "Iteration 35, loss = 0.00481785\n",
      "Iteration 36, loss = 0.00410938\n",
      "Iteration 37, loss = 0.00362750\n",
      "Iteration 38, loss = 0.00313895\n",
      "Iteration 39, loss = 0.00292634\n",
      "Iteration 40, loss = 0.00280471\n",
      "Iteration 41, loss = 0.00269330\n",
      "Iteration 42, loss = 0.00258212\n",
      "Iteration 43, loss = 0.00248700\n",
      "Iteration 44, loss = 0.00239928\n",
      "Iteration 45, loss = 0.00236318\n",
      "Iteration 46, loss = 0.00231176\n",
      "Iteration 47, loss = 0.00225418\n",
      "Iteration 48, loss = 0.00220760\n",
      "Iteration 49, loss = 0.00217278\n",
      "Iteration 50, loss = 0.00212965\n",
      "Iteration 51, loss = 0.00210170\n",
      "Iteration 52, loss = 0.00207576\n",
      "Iteration 53, loss = 0.00204339\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Training accuracy: 1.0\n",
      "Testing accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "reg4 = MLPClassifier(hidden_layer_sizes=(256, 128, 64), verbose = True, solver='sgd', activation='tanh',learning_rate='constant', learning_rate_init=0.1, batch_size=128, max_iter=100)\n",
    "reg4.fit(train_x, train_y)\n",
    "t = reg4.score(train_x,train_y)\n",
    "tt = reg4.score(test_x, test_y)\n",
    "print('Training accuracy:',t)\n",
    "print('Testing accuracy:',tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBf5KApCdes_"
   },
   "outputs": [],
   "source": [
    "dbfile = open('/content/gdrive/My Drive/ML/Assignment3/q1/sklearn_tanh', 'ab')\n",
    "pickle.dump(reg4, dbfile)                      \n",
    "dbfile.close() "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "q1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
